\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsthm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

\begin{document}

\section{Taylor Expansions: From Scalar to ODE}

\subsection{One-dimensional case}

\begin{theorem}[Taylor's theorem with integral remainder, $C^{N+1}$ scalar case]
Let $f:\mathbb{R} \to \mathbb{R}$ be $C^{N+1}$ and let $a,h \in \mathbb{R}$. Then
\[
f(a+h) = \sum_{k=0}^N \frac{f^{(k)}(a)}{k!} h^k 
+ \frac{h^{N+1}}{N!} \int_0^1 (1-\theta)^N f^{(N+1)}(a + \theta h)\,d\theta.
\]
\end{theorem}

\begin{proof}[Outline of the Proof]
Apply the fundamental theorem of calculus to $f$ and $f^{(k)}$ repeatedly, 
swap the order of integration (Fubini), and identify the weight $(1-\theta)^N$ 
as the measure of a simplex in the $(\theta_1,\dots,\theta_{N+1})$ integration domain.
\end{proof}

\begin{lemma}[Special cases]
For $N=1$, the remainder reduces to
\[
R_2 = h^2 \int_0^1 (1-\theta) f''(a+\theta h)\,d\theta.
\]
For $f''$ constant, this gives the familiar $\frac{1}{2}f''(a)h^2$ term.
\end{lemma}

\medskip

\subsection*{Remark on the tensor notation in multivariate Taylor expansions}

In the one-dimensional Taylor theorem, the $k$-th derivative $f^{(k)}(a)$ is a scalar 
and the monomial term is $h^k \in \mathbb{R}$. 
In the multivariate case $F:\mathbb{R}^d \to \mathbb{R}^m$, the $k$-th derivative 
at $a$ is a \emph{$k$-linear map} 
\[
D^kF(a) \in \mathcal{L}\big((\mathbb{R}^d)^k, \mathbb{R}^m\big),
\]
i.e.\ an element of the Banach space of bounded $k$-linear maps 
$(\mathbb{R}^d)^k \to \mathbb{R}^m$.

Formally, starting from the Fr\'echet derivative definition,
\[
D^1F(a) \in \mathcal{L}(\mathbb{R}^d, \mathbb{R}^m), \quad
D^2F(a) \in \mathcal{L}\big(\mathbb{R}^d, \mathcal{L}(\mathbb{R}^d, \mathbb{R}^m)\big),
\]
and so on. Using the canonical isomorphisms
\[
\mathcal{L}\big(\mathbb{R}^d, \mathcal{L}(\mathbb{R}^d, G)\big) 
\;\cong\; \mathcal{L}(\mathbb{R}^d \times \mathbb{R}^d, G),
\]
we can ``flatten'' this to $D^kF(a) \in \mathcal{L}((\mathbb{R}^d)^k, \mathbb{R}^m)$.

Given a vector $h\in\mathbb{R}^d$, the notation
\[
D^kF(a)[h^{\otimes k}]
\]
means that we evaluate $D^kF(a)$ on $k$ identical arguments $h$, 
and $h^{\otimes k} \in (\mathbb{R}^d)^{\otimes k}$ denotes the 
\emph{$k$-fold tensor power} of $h$. 
This notation is convenient because:
\begin{itemize}
\item in the scalar case $d=1$, $h^{\otimes k}$ reduces to $h^k$;
\item $D^kF(a)$ can be viewed as an element of the dual of $(\mathbb{R}^d)^{\otimes k}$, 
acting linearly on $h^{\otimes k}$.
\end{itemize}

\paragraph{Connection to ODE expansions.}
In the expansion of an ODE driven by a $d$-dimensional bounded variation path
\[
dy_t = \sum_{i=1}^d V_i(y_t)\,dx_t^i,
\]
the role of the monomial $h^{\otimes k}$ is played by the 
\emph{iterated integrals} of $x$,
\[
\mathbf{X}^{i_1,\dots,i_k}_{s,t} 
:= \int_{s<u_1<\cdots<u_k<t} dx^{i_1}_{u_1} \cdots dx^{i_k}_{u_k} \in (\mathbb{R}^d)^{\otimes k}.
\]
The coefficients $D^kF(a)$ become \emph{compositions of directional derivatives}:
\[
D^kF(a)[e_{i_1},\dots,e_{i_k}] 
= \big(D_{V_{i_k}}\cdots D_{V_{i_1}}\mathrm{Id}\big)(a),
\]
where $\{e_i\}$ is the standard basis of $\mathbb{R}^d$ and $D_{V_i}$ denotes the derivative along $V_i$.
Thus, the multivariate Taylor series
\[
\sum_{k=0}^N \frac{1}{k!} D^kF(a)[h^{\otimes k}]
\]
is replaced in the ODE setting by the \emph{Chen--Taylor expansion}
\[
\sum_{k=0}^N \ \sum_{i_1,\dots,i_k} 
\big(D_{V_{i_k}}\cdots D_{V_{i_1}}\mathrm{Id}\big)(y_s) \ \mathbf{X}^{i_1,\dots,i_k}_{s,t}.
\]
The tensor power $h^{\otimes k}$ is thus replaced by the $k$-th level of the 
\emph{signature} of the driving path $x$.

\subsection{Chain rules (Fr\'echet viewpoint)}

\begin{theorem}[Chain rule, first order]
Let $G:U\subset\mathbb{R}^p\to\mathbb{R}^m$ and $F:V\subset\mathbb{R}^m\to\mathbb{R}^n$
be $C^1$, with $G(U)\subset V$. Then $F\circ G$ is $C^1$ and
\[
D(F\circ G)(x) \;=\; DF(G(x)) \circ DG(x).
\]
Equivalently, for $h\in\mathbb{R}^p$,
\[
D(F\circ G)(x)[h] \;=\; DF(G(x))\big[\,DG(x)[h]\,\big].
\]
\end{theorem}

\begin{proof}[Outline of the Proof]
Use the definition of Fr\'echet derivative and the linear approximation error for $F$ and $G$, then collect $o(\|h\|)$ terms.
\end{proof}

\begin{proposition}[Second-order chain rule]
If $F\in C^2$ and $G\in C^2$, then $F\circ G\in C^2$ and for $h,k\in\mathbb{R}^p$,
\[
\begin{aligned}
D^2(F\circ G)(x)[h,k]
&= D^2F(G(x))\big[\,DG(x)[h],\,DG(x)[k]\,\big]
\\[-2pt]&\qquad +\, DF(G(x))\big[\,D^2G(x)[h,k]\,\big].
\end{aligned}
\]
In particular, $D^2(F\circ G)(x)$ is symmetric bilinear.
\end{proposition}

\begin{proof}[Outline]
Differentiate the first-order chain rule once more and apply the product rule for multilinear maps.
\end{proof}

\begin{theorem}[Higher-order chain rule (multilinear Fa\`a di Bruno)]
If $F\in C^{N}$ and $G\in C^{N}$, then $F\circ G\in C^{N}$. For $k\le N$ and $h_1,\dots,h_k\in\mathbb{R}^p$,
\[
D^{k}(F\circ G)(x)[h_1,\dots,h_k]
=\!\!\sum_{\pi\in \mathcal{P}_k}\!\!
D^{|\pi|}F(G(x))\Big[\, D^{|B_1|}G(x)[h_{B_1}],\dots, D^{|B_{|\pi|}|}G(x)[h_{B_{|\pi|}}]\,\Big],
\]
where the sum is over all set partitions $\pi=\{B_1,\dots,B_{|\pi|}\}$ of $\{1,\dots,k\}$ and
$h_{B}:=(h_i)_{i\in B}$.
\end{theorem}

\begin{proof}[Outline]
Induct on $k$, using the bilinear product rule and symmetry of Fr\'echet derivatives; this is the standard multilinear Fa\`a di Bruno formula.
\end{proof}

\paragraph{Corollaries for paths.}
Let $y:[0,1]\to\mathbb{R}^m$ be $C^{N}$ and set $g(t):=F(y(t))$.
Then $g^{(k)}(t)=D^{k}F(y(t))[y'(t)^{\otimes k}]$ for $k\le N$.
In particular, for an affine path $y(t)=a+th$,
\[
g^{(k)}(t)=D^{k}F(a+th)\big[h^{\otimes k}\big],
\]
which is exactly the identity used in the multivariate Taylor derivation.

\paragraph{BV-driven ODE (chain rule along the flow).}
If $x:[0,T]\to\mathbb{R}^d$ has bounded variation and
$dy_t=\sum_{i=1}^d V_i(y_t)\,dx_t^i$ with smooth $V_i$, then for any $F\in C^1$,
\[
dF(y_t) \;=\; \sum_{i=1}^d DF(y_t)\big[V_i(y_t)\big]\,dx_t^i,
\]
i.e.\ $F(y_t)-F(y_s)=\sum_i \int_s^t DF(y_u)[V_i(y_u)]\,dx_u^i$ (plain Riemann--Stieltjes).


\subsection{Multivariate case}

\begin{theorem}[Multivariate Taylor expansion with integral remainder]
Let $F:U\subset\mathbb{R}^m\to\mathbb{R}^n$ be $C^{N+1}$, $a\in U$, and $h\in\mathbb{R}^m$
such that $a+\theta h\in U$ for all $\theta\in[0,1]$. Then
\[
F(a+h)
= \sum_{k=0}^{N} \frac{1}{k!}\,D^kF(a)\big[h^{\otimes k}\big]
 \;+\; \frac{1}{N!}\int_0^1 (1-\theta)^N\,D^{N+1}F(a+\theta h)\big[h^{\otimes(N+1)}\big]\,d\theta.
\]
Here $D^kF(a)$ is the $k$-linear Fr\'echet derivative, and $h^{\otimes k}$ is the $k$-fold tensor power of $h$.
\end{theorem}

\begin{proof}[Step-by-step derivation]
\textbf{Step 1 (Reduce to a scalar one-variable function).}
Fix $a,h$ and set
\[
g:[0,1]\to\mathbb{R}^n,\qquad g(t):=F(a+th).
\]
By the chain rule in Banach spaces, $g$ is $C^{N+1}$ and
\[
g^{(k)}(t)=D^kF(a+th)\big[h^{\otimes k}\big]\quad (k\ge 1).
\]

\medskip
\textbf{Step 2 (Iterate the Fundamental Theorem of Calculus).}
Apply FTC once:
\[
g(1)=g(0)+\int_0^1 g'(t_1)\,dt_1.
\]
Apply FTC to $g'$ on $[0,t_1]$, then to $g''$ on $[0,t_2]$, and so on, $N$ times. Inductively one shows
\[
g(1)
= \sum_{k=0}^{N}\frac{g^{(k)}(0)}{k!}
 \;+\; \int_{0<t_{N+1}<\cdots<t_1<1} g^{(N+1)}(t_{N+1})\,dt_{N+1}\cdots dt_1.
\]
(The coefficients $1/k!$ come from the volume of the $k$-simplex.)

\medskip
\textbf{Step 3 (Evaluate the simplex integral).}
Integrate out $t_1,\dots,t_N$ with $t_{N+1}$ fixed:
\[
\int_{t_{N+1}<\cdots<t_1<1} dt_1\cdots dt_N
= \frac{(1-t_{N+1})^N}{N!}.
\]
Thus
\[
\int_{0<t_{N+1}<\cdots<t_1<1} g^{(N+1)}(t_{N+1})\,dt_{N+1}\cdots dt_1
= \frac{1}{N!}\int_0^1 (1-\theta)^N\,g^{(N+1)}(\theta)\,d\theta.
\]

\medskip
\textbf{Step 4 (Rewrite in terms of Fr\'echet derivatives).}
Recall $g^{(k)}(0)=D^kF(a)[h^{\otimes k}]$ and
$g^{(N+1)}(\theta)=D^{N+1}F(a+\theta h)[h^{\otimes (N+1)}]$.
Substitute these into the formula from Steps 2–3 to obtain
\[
F(a+h)=\sum_{k=0}^{N}\frac{1}{k!}D^kF(a)[h^{\otimes k}]
+\frac{1}{N!}\int_0^1 (1-\theta)^N D^{N+1}F(a+\theta h)[h^{\otimes (N+1)}]\,d\theta.
\]
\end{proof}

\begin{lemma}[Symmetry and norms]
If $F\in C^{N+1}$ then $D^kF(a)$ is symmetric $k$-linear. Moreover, if
$\|D^{N+1}F(x)\|\le M$ on $\{a+\theta h:\theta\in[0,1]\}$, then
\[
\big\|F(a+h)-\sum_{k=0}^{N}\tfrac{1}{k!}D^kF(a)[h^{\otimes k}]\big\|
\le \frac{M}{(N+1)!}\,\|h\|^{N+1}.
\]
\end{lemma}

\begin{proof}[Outline]
Symmetry is Clairaut’s theorem (equality of mixed partials) in Fr\'echet form. The bound follows by estimating the integral remainder using $\|(1-\theta)^N\|_{L^1}=1/(N+1)$ and $\|h^{\otimes (N+1)}\|=\|h\|^{N+1}$.
\end{proof}

\begin{proposition}[Order estimate]
If $\|D^{N+1}F\|_\infty \le M$ on the segment $\{a+\theta h: \theta\in[0,1]\}$, 
then the remainder satisfies 
\[
\|R_{N+1}\| \le \frac{M}{(N+1)!} \|h\|^{N+1}.
\]
\end{proposition}

\medskip

\subsection{Application: ODE driven by BV paths}

\begin{theorem}[Chen--Taylor expansion from the integral form]
Let $x:[0,T]\to\mathbb{R}^d$ be of bounded variation and $V_1,\dots,V_d\in C^{N+1}_b(\mathbb{R}^m;\mathbb{R}^m)$.
For $s<t$ the solution of
\[
y_t \;=\; y_s \;+\; \sum_{i=1}^d \int_s^t V_i(y_u)\,dx_u^i
\]
admits, for the $k$-fold iterated Riemann--Stieltjes integrals
\(
\mathbf X^{i_1,\dots,i_k}_{s,t}:=\int_{s<u_1<\cdots<u_k<t} dx_{u_1}^{i_1}\cdots dx_{u_k}^{i_k},
\)
the expansion
\[
y_t \;=\; y_s \;+\; \sum_{k=1}^N \ \sum_{i_1,\dots,i_k=1}^d
\big(D_{V_{i_k}}\cdots D_{V_{i_1}}\mathrm{Id}\big)(y_s)\ \mathbf X^{i_1,\dots,i_k}_{s,t}
\;+\; R^{(N)}_{s,t},
\]
with $\|R^{(N)}_{s,t}\|\le C_N\,\mathrm{Var}(x;[s,t])^{N+1}$. Here $D_{V}F:=(DF)\cdot V$.
\end{theorem}

\begin{proof}[Outline of the Proof (from the integral form, showing the chain rule)]
Fix $s<t$. Start directly from
\[
y_t-y_s \;=\; \sum_{i=1}^d \int_s^t V_i(y_u)\,dx_u^i.
\]

\emph{Level 1.}  
Apply the $0$-th order Taylor formula at $y_s$:
\[
V_i(y_u)
= V_i(y_s) 
+ \underbrace{\int_0^1 
    DV_i\!\big(y_s+\theta(y_u-y_s)\big)
    [\,y_u-y_s\,]\,d\theta}_{=:E_i(s,u)}.
\]
Integrating in $u$ gives
\[
y_t
= y_s + \sum_i V_i(y_s)\,\mathbf X^i_{s,t} 
  + \sum_i \int_s^t E_i(s,u)\,dx_u^i,
\]
i.e.\ the Euler term with coefficient 
$D_{V_i}\mathrm{Id}(y_s) = V_i(y_s)$,  
plus a remainder $\mathcal O(\omega^2)$,  
where $\omega := \mathrm{Var}(x;[s,t])$.

\medskip
\emph{Level 2 (explicit substitution into $E_i$; chain rule appears).}  
Let $h(u) := y_u-y_s$.  
From the integral form,
\[
h(u) \;=\; \sum_{j=1}^d \int_s^u V_j(y_v)\,dx_v^j.
\]
Decompose
\[
V_j(y_v)
= V_j(y_s) + \Delta_j(s,v),
\quad
\Delta_j(s,v)
:= \int_0^1 DV_j\!\big(y_s+\lambda(y_v-y_s)\big)
   [\,y_v-y_s\,]\,d\lambda.
\]

Then
\begin{align*}
\int_s^t E_i(s,u)\,dx_u^i
&= \int_s^t \!\int_0^1 
       DV_i\!\big(y_s+\theta h(u)\big)
       \Big[\,\sum_j \int_s^u 
             \big(V_j(y_s)+\Delta_j(s,v)\big)\,dx_v^j
       \Big]
     d\theta\,dx_u^i \\
&= \sum_j A_{i,j} + \sum_j B_{i,j},
\end{align*}
where
\begin{align*}
A_{i,j} 
&:= \int_s^t \!\int_0^1 
       DV_i\!\big(y_s+\theta h(u)\big)
       [\,V_j(y_s)\,]\,d\theta 
       \;\Big(\int_s^u dx_v^j\Big)\,dx_u^i, \\
B_{i,j} 
&:= \int_s^t \!\int_0^1 
       DV_i\!\big(y_s+\theta h(u)\big)
       \Big[\,\int_s^u \Delta_j(s,v)\,dx_v^j\Big]
       d\theta\,dx_u^i.
\end{align*}

\smallskip
\noindent\textit{Main second-order term (from $A_{i,j}$).}  
Split
\[
A_{i,j}
= \int_s^t DV_i(y_s)[V_j(y_s)]
    \;\Big(\int_s^u dx_v^j\Big)\,dx_u^i
 + \mathcal O(\omega^3).
\]
The leading part equals
\[
DV_i(y_s)[V_j(y_s)]\,\mathbf X^{j,i}_{s,t}
= \big(D_{V_j}V_i\big)(y_s)\,\mathbf X^{j,i}_{s,t}
= \big(D_{V_j}D_{V_i}\mathrm{Id}\big)(y_s)\,\mathbf X^{j,i}_{s,t},
\]
by the chain rule and $V_i = D_{V_i}\mathrm{Id}$.

\smallskip
\noindent\textit{Error terms (from $B_{i,j}$).}  
From $\|\Delta_j(s,v)\| \lesssim \omega(s,v)$,  
\[
\left\|\int_s^u \Delta_j(s,v)\,dx_v^j\right\| 
\lesssim \omega(s,u)^2,
\]
so $B_{i,j} = \mathcal O(\omega^3)$ after integration.

\smallskip
Collecting terms over $i,j$ yields the level-2 contribution
\[
\sum_{i,j} 
   \big(D_{V_j}D_{V_i}\mathrm{Id}\big)(y_s)\,\mathbf X^{j,i}_{s,t}
\]
plus a remainder $\mathcal O(\omega^3)$.

\medskip
\emph{Level 3 and higher.}  
Proceed similarly:  
retain higher Taylor terms, substitute $h$ by its lower-order approximation, freeze coefficients at $y_s$, and integrate.  
Each derivative of $V$ applied to frozen vectors $V_\bullet(y_s)$ turns into a composition $D_{V_\bullet}\cdots D_{V_i}\mathrm{Id}$ by the chain rule.  
Nested integrals produce $\mathbf X^{\cdot}_{s,t}$, while terms with extra $h$ factors go into the higher-order remainder.  
Induction completes the proof.
\end{proof}


\begin{proposition}[Remainder bound]
Let $\omega(s,t) := \mathrm{Var}(x;[s,t])$ be the variation of $x$ on $[s,t]$.
Then there exists $C_N>0$ (depending on $\sup\|D^\ell V_i\|$, $\ell\le N+1$) such that
\[
\|R^{(N)}_{s,t}\| \le C_N \ \omega(s,t)^{N+1}.
\]
If $x$ is $C^1$, then $\omega(s,t) \lesssim |t-s|$, so $\|R^{(N)}_{s,t}\| = O(|t-s|^{N+1})$.
\end{proposition}

\medskip
\noindent\textbf{Comment.} This expansion is the smooth-path analogue of the signature/rough path expansion: the coefficients are given by iterated Lie derivatives of the identity along the vector fields $V_i$, and the ``monomials'' are the iterated integrals of the driving signal $x$.

\end{document}
